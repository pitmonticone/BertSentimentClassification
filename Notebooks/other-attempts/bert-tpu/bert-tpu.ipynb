{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "This notebook produces an error we could not solve: a [related issue](https://www.kaggle.com/general/141350) has been posted on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/bert-for-tf2/py-params-0.8.2/py-params-0.8.2\n",
      "Building wheels for collected packages: py-params\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-params: filename=py_params-0.8.2-py3-none-any.whl size=4632 sha256=407e31cf8ea84a13519da41a3f6c24f1b0fe7418ea998c813e02543241630ec6\n",
      "  Stored in directory: /root/.cache/pip/wheels/51/4d/e7/66d3d48420c6b97ada4739885ff670f5fe0e7f062e7c837e50\n",
      "Successfully built py-params\n",
      "Installing collected packages: py-params\n",
      "Successfully installed py-params-0.8.2\n",
      "Processing /kaggle/input/bert-for-tf2/params-flow-0.7.4/params-flow-0.7.4\n",
      "Requirement already satisfied: py-params>=0.6.4 in /opt/conda/lib/python3.6/site-packages (from params-flow==0.7.4) (0.8.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from params-flow==0.7.4) (1.18.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from params-flow==0.7.4) (4.42.0)\n",
      "Building wheels for collected packages: params-flow\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for params-flow: filename=params_flow-0.7.4-py3-none-any.whl size=16194 sha256=d6bab5c8b5fd50a67c0e866dc6f6ad84e6733487e979f9a9fefd8b38480b5325\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/47/aa/df889d7c3cc5194153ae36670542eb434b4ef5cdbe8969e3ab\n",
      "Successfully built params-flow\n",
      "Installing collected packages: params-flow\n",
      "Successfully installed params-flow-0.7.4\n",
      "Processing /kaggle/input/bert-for-tf2/bert-for-tf2-0.13.2/bert-for-tf2-0.13.2\n",
      "Requirement already satisfied: py-params>=0.7.3 in /opt/conda/lib/python3.6/site-packages (from bert-for-tf2==0.13.2) (0.8.2)\n",
      "Requirement already satisfied: params-flow>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from bert-for-tf2==0.13.2) (0.7.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from params-flow>=0.7.1->bert-for-tf2==0.13.2) (1.18.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from params-flow>=0.7.1->bert-for-tf2==0.13.2) (4.42.0)\n",
      "Building wheels for collected packages: bert-for-tf2\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.13.2-py3-none-any.whl size=50796 sha256=72d5c395980e8ff3233495e522c822c464a6d6d1ae9e9cd4a4994b78b2a992f2\n",
      "  Stored in directory: /root/.cache/pip/wheels/4d/2f/3f/79ede29f4af134d43f5a5bf7e0d3b2ec98379c7fa939769f51\n",
      "Successfully built bert-for-tf2\n",
      "Installing collected packages: bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.13.2\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.85)\n"
     ]
    }
   ],
   "source": [
    "#run only once per kaggle session\n",
    "!pip install /kaggle/input/bert-for-tf2/py-params-0.8.2/py-params-0.8.2/\n",
    "!pip install /kaggle/input/bert-for-tf2/params-flow-0.7.4/params-flow-0.7.4/\n",
    "!pip install /kaggle/input/bert-for-tf2/bert-for-tf2-0.13.2/bert-for-tf2-0.13.2/\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "assert not tf.executing_eagerly()\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "print(\"REPLICAS: \", tpu_strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "with open('../input/imbddata/train_input.pickle', 'rb') as f:\n",
    "     train_input= pickle.load(f)\n",
    "\n",
    "    \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 768)]        0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          393728      tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/Shape (Tens [(2,)]               0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/random_unif [(None, 512)]        0           tf_op_layer_dropout/Shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/random_unif [(None, 512)]        0           tf_op_layer_dropout/random_unifor\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/random_unif [(None, 512)]        0           tf_op_layer_dropout/random_unifor\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/GreaterEqua [(None, 512)]        0           tf_op_layer_dropout/random_unifor\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/mul (Tensor [(None, 512)]        0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/Cast (Tenso [(None, 512)]        0           tf_op_layer_dropout/GreaterEqual[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_dropout/mul_1 (Tens [(None, 512)]        0           tf_op_layer_dropout/mul[0][0]    \n",
      "                                                                 tf_op_layer_dropout/Cast[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         tf_op_layer_dropout/mul_1[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 109,876,482\n",
      "Trainable params: 109,876,481\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "From /job:worker/replica:0/task:0:\nUnsuccessful TensorSliceReader constructor: Failed to get matching files on /tmp/tfhub_modules/041d84cb334a865509a787b4c9177fb6c7bba8c2/variables/variables: Unimplemented: File system scheme '[local]' not implemented (file: '/tmp/tfhub_modules/041d84cb334a865509a787b4c9177fb6c7bba8c2/variables/variables')\n\t [[node RestoreV2 (defined at /opt/conda/lib/python3.6/site-packages/tensorflow_hub/module_v2.py:95) ]]\n\nOriginal stack trace for 'RestoreV2':\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1199, in inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1113, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 315, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 315, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 315, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-2e09d738c9f0>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', '\\n\\nmax_seq_length = 512  \\nmax_len = max_seq_length\\ndropouts = [0.3, 0.4,0.5] #0.6 già fatto\\n\\n\\nfor drop in dropouts:\\n    with tpu_strategy.scope():\\n        with open(\\'../input/imbddata/train_input.pickle\\', \\'rb\\') as f:\\n             train_input= pickle.load(f)\\n        train_labels = np.load(\"../input/imbddata/train_labels.npy\")\\n        METRICS = [ tensorflow.keras.metrics.BinaryAccuracy(name=\\'accuracy\\'), tensorflow.keras.metrics.AUC(name=\\'auc\\')]\\n        \\n        input_word_ids = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\\n        input_mask = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\\n        segment_ids = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\\n        bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/./bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)\\n        _ , sequence_output = bert_layer([input_word_ids, input_mask, segment_ids]) \\n        clf_output = sequence_output[:, 0, :] \\n        mean = tf.reduce_mean(sequence_output, 1) #testare due opzioni\\n        out = tensorflow.keras.layers.Dense(512, activation=\\'relu\\')(mean)\\n        out = tf.nn.dropout(out,drop)\\n        final = tensorflow.keras.layers.Dense(1, activation=\\'sigmoid\\')(out)\\n        model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=final)\\n        model.compile(Adam(lr=2e-6), loss=\\'binary_crossentropy\\', metrics=METRICS)\\n    model.summary()\\n    train_labels = train_labels.astype(float)\\n    history = model.fit(\\n    train_input, train_labels,\\n    validation_split=0.2,\\n    epochs=6,\\n    batch_size=128* tpu_strategy.num_replicas_in_sync, #12\\n    verbose = 100)\\n    with open(\\'../working/trainHistoryDict\\'+\\'_\\'+str(drop), \\'wb\\') as file_pi:\\n        pickle.dump(history.history, file_pi)\\n    \\n    plt.plot(history.history[\\'accuracy\\'])\\n    plt.plot(history.history[\\'val_accuracy\\'])\\n    plt.title(\\'model accuracy_\\'+str(drop))\\n    plt.ylabel(\\'accuracy\\')\\n    plt.xlabel(\\'epoch\\')\\n    plt.legend([\\'train\\', \\'test\\'], loc=\\'upper left\\')\\n    plt.savefig(r\"../working/accuracy\"+\"_\"+str(drop)+\".png\")\\n    plt.show()\\n    \\n    # summarize history for loss\\n    plt.plot(history.history[\\'loss\\'])\\n    plt.plot(history.history[\\'val_loss\\'])\\n    plt.title(\\'model loss_\\'+str(drop))\\n    plt.ylabel(\\'loss\\')\\n    plt.xlabel(\\'epoch\\')\\n    plt.legend([\\'train\\', \\'test\\'], loc=\\'upper left\\')\\n    plt.savefig(r\"../working/loss\"+\"_\"+str(drop)+\".png\")\\n    plt.show()\\n    \\n    # summarize histry for roc\\n    # summarize history for loss\\n    plt.plot(history.history[\\'auc\\'])\\n    plt.plot(history.history[\\'val_auc\\'])\\n    plt.title(\\'model roc_\\'+str(drop))\\n    plt.ylabel(\\'roc\\')\\n    plt.xlabel(\\'epoch\\')\\n    plt.legend([\\'train\\', \\'test\\'], loc=\\'upper left\\')\\n    plt.savefig(r\"../working/roc\"+\"_\"+str(drop)+\".png\")\\n    plt.show()\\n')\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2362, in run_cell_magic\n    result = fn(*args, **kwargs)\n  File \"<decorator-gen-61>\", line 2, in time\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1312, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 16, in <module>\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_hub/keras_layer.py\", line 137, in __init__\n    self._func = load_module(handle, tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_hub/keras_layer.py\", line 352, in load_module\n    return module_v2.load(handle, tags=tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_hub/module_v2.py\", line 95, in load\n    obj = tf_v1.saved_model.load_v2(module_path, tags=tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 528, in load\n    return load_internal(export_dir, tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 552, in load_internal\n    export_dir)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 128, in __init__\n    self._restore_checkpoint()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 280, in _restore_checkpoint\n    load_status = saver.restore(variables_path)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1283, in restore\n    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 209, in restore\n    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 908, in _restore_from_checkpoint_position\n    tensor_saveables, python_saveables))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 289, in restore_saveables\n    validated_saveables).restore(self.save_path_tensor)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 255, in restore\n    restore_ops.update(saver.restore(file_prefix))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 95, in restore\n    file_prefix, tensor_names, tensor_slices, tensor_dtypes)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1506, in restore_v2\n    name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1351\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1352\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1444\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: From /job:worker/replica:0/task:0:\nUnsuccessful TensorSliceReader constructor: Failed to get matching files on /tmp/tfhub_modules/041d84cb334a865509a787b4c9177fb6c7bba8c2/variables/variables: Unimplemented: File system scheme '[local]' not implemented (file: '/tmp/tfhub_modules/041d84cb334a865509a787b4c9177fb6c7bba8c2/variables/variables')\n\t [[{{node RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         epochs=epochs)\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdist_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_distributing_by_cloning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_distribution_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch)\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m       \u001b[0mfirst_x_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 960\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1183\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1361\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1384\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1386\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: From /job:worker/replica:0/task:0:\nUnsuccessful TensorSliceReader constructor: Failed to get matching files on /tmp/tfhub_modules/041d84cb334a865509a787b4c9177fb6c7bba8c2/variables/variables: Unimplemented: File system scheme '[local]' not implemented (file: '/tmp/tfhub_modules/041d84cb334a865509a787b4c9177fb6c7bba8c2/variables/variables')\n\t [[node RestoreV2 (defined at /opt/conda/lib/python3.6/site-packages/tensorflow_hub/module_v2.py:95) ]]\n\nOriginal stack trace for 'RestoreV2':\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1199, in inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1113, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 315, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 315, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 315, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-2e09d738c9f0>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', '\\n\\nmax_seq_length = 512  \\nmax_len = max_seq_length\\ndropouts = [0.3, 0.4,0.5] #0.6 già fatto\\n\\n\\nfor drop in dropouts:\\n    with tpu_strategy.scope():\\n        with open(\\'../input/imbddata/train_input.pickle\\', \\'rb\\') as f:\\n             train_input= pickle.load(f)\\n        train_labels = np.load(\"../input/imbddata/train_labels.npy\")\\n        METRICS = [ tensorflow.keras.metrics.BinaryAccuracy(name=\\'accuracy\\'), tensorflow.keras.metrics.AUC(name=\\'auc\\')]\\n        \\n        input_word_ids = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\\n        input_mask = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\\n        segment_ids = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\\n        bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/./bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)\\n        _ , sequence_output = bert_layer([input_word_ids, input_mask, segment_ids]) \\n        clf_output = sequence_output[:, 0, :] \\n        mean = tf.reduce_mean(sequence_output, 1) #testare due opzioni\\n        out = tensorflow.keras.layers.Dense(512, activation=\\'relu\\')(mean)\\n        out = tf.nn.dropout(out,drop)\\n        final = tensorflow.keras.layers.Dense(1, activation=\\'sigmoid\\')(out)\\n        model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=final)\\n        model.compile(Adam(lr=2e-6), loss=\\'binary_crossentropy\\', metrics=METRICS)\\n    model.summary()\\n    train_labels = train_labels.astype(float)\\n    history = model.fit(\\n    train_input, train_labels,\\n    validation_split=0.2,\\n    epochs=6,\\n    batch_size=128* tpu_strategy.num_replicas_in_sync, #12\\n    verbose = 100)\\n    with open(\\'../working/trainHistoryDict\\'+\\'_\\'+str(drop), \\'wb\\') as file_pi:\\n        pickle.dump(history.history, file_pi)\\n    \\n    plt.plot(history.history[\\'accuracy\\'])\\n    plt.plot(history.history[\\'val_accuracy\\'])\\n    plt.title(\\'model accuracy_\\'+str(drop))\\n    plt.ylabel(\\'accuracy\\')\\n    plt.xlabel(\\'epoch\\')\\n    plt.legend([\\'train\\', \\'test\\'], loc=\\'upper left\\')\\n    plt.savefig(r\"../working/accuracy\"+\"_\"+str(drop)+\".png\")\\n    plt.show()\\n    \\n    # summarize history for loss\\n    plt.plot(history.history[\\'loss\\'])\\n    plt.plot(history.history[\\'val_loss\\'])\\n    plt.title(\\'model loss_\\'+str(drop))\\n    plt.ylabel(\\'loss\\')\\n    plt.xlabel(\\'epoch\\')\\n    plt.legend([\\'train\\', \\'test\\'], loc=\\'upper left\\')\\n    plt.savefig(r\"../working/loss\"+\"_\"+str(drop)+\".png\")\\n    plt.show()\\n    \\n    # summarize histry for roc\\n    # summarize history for loss\\n    plt.plot(history.history[\\'auc\\'])\\n    plt.plot(history.history[\\'val_auc\\'])\\n    plt.title(\\'model roc_\\'+str(drop))\\n    plt.ylabel(\\'roc\\')\\n    plt.xlabel(\\'epoch\\')\\n    plt.legend([\\'train\\', \\'test\\'], loc=\\'upper left\\')\\n    plt.savefig(r\"../working/roc\"+\"_\"+str(drop)+\".png\")\\n    plt.show()\\n')\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2362, in run_cell_magic\n    result = fn(*args, **kwargs)\n  File \"<decorator-gen-61>\", line 2, in time\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1312, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 16, in <module>\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_hub/keras_layer.py\", line 137, in __init__\n    self._func = load_module(handle, tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_hub/keras_layer.py\", line 352, in load_module\n    return module_v2.load(handle, tags=tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_hub/module_v2.py\", line 95, in load\n    obj = tf_v1.saved_model.load_v2(module_path, tags=tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 528, in load\n    return load_internal(export_dir, tags)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 552, in load_internal\n    export_dir)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 128, in __init__\n    self._restore_checkpoint()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\", line 280, in _restore_checkpoint\n    load_status = saver.restore(variables_path)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1283, in restore\n    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 209, in restore\n    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 908, in _restore_from_checkpoint_position\n    tensor_saveables, python_saveables))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 289, in restore_saveables\n    validated_saveables).restore(self.save_path_tensor)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 255, in restore\n    restore_ops.update(saver.restore(file_prefix))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 95, in restore\n    file_prefix, tensor_names, tensor_slices, tensor_dtypes)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1506, in restore_v2\n    name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "max_seq_length = 512  \n",
    "max_len = max_seq_length\n",
    "dropouts = [0.3, 0.4,0.5] #0.6 già fatto\n",
    "\n",
    "\n",
    "for drop in dropouts:\n",
    "    with tpu_strategy.scope():\n",
    "        with open('../input/imbddata/train_input.pickle', 'rb') as f:\n",
    "             train_input= pickle.load(f)\n",
    "        train_labels = np.load(\"../input/imbddata/train_labels.npy\")\n",
    "        METRICS = [ tensorflow.keras.metrics.BinaryAccuracy(name='accuracy'), tensorflow.keras.metrics.AUC(name='auc')]\n",
    "        \n",
    "        input_word_ids = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "        input_mask = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "        segment_ids = tensorflow.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "        bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/./bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)\n",
    "        _ , sequence_output = bert_layer([input_word_ids, input_mask, segment_ids]) \n",
    "        clf_output = sequence_output[:, 0, :] \n",
    "        mean = tf.reduce_mean(sequence_output, 1) #testare due opzioni\n",
    "        out = tensorflow.keras.layers.Dense(512, activation='relu')(mean)\n",
    "        out = tf.nn.dropout(out,drop)\n",
    "        final = tensorflow.keras.layers.Dense(1, activation='sigmoid')(out)\n",
    "        model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=final)\n",
    "        model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=METRICS)\n",
    "    model.summary()\n",
    "    train_labels = train_labels.astype(float)\n",
    "    history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=6,\n",
    "    batch_size=128* tpu_strategy.num_replicas_in_sync, #12\n",
    "    verbose = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
